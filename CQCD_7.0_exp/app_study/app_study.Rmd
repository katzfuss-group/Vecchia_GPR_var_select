---
title: "Application Study"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Method 
Bridge penalty solution path, forward-backward selection, and CQCD. Predictor selection and CQCD are run with mini-batching.

## Preparation
Clean the environment
```{r clean environment}
rm(list = ls())
```
Need to install a modified version of the GpGp R package.
```{r install the moderated GpGp Pkg}
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
library(FNN)
library(parallel)
library(scoringRules)
if(file.exists("CQCD.R")){
  source("CQCD.R")
}else{
  source("../CQCD.R")
}
source("vecchia_scaled.R")
```

Function for computing the approximate OOS score, assuming the squared relevance parameterized Matern25 kernel.
```{r OOS score, eval = T}
OOS_score <- function(theta, m)
{
  idxLocsRel <- which(theta[2 : (d + 1)] > 0)
  dRel <- length(idxLocsRel)
  locsRel <- rbind(locsTrain, locsOOS)[, idxLocsRel, drop = F]
  thetaRel <- theta[c(1, idxLocsRel + 1, d + 2)]
  locsRelScal <- locsRel %*% 
    diag(sqrt(thetaRel[2 : (dRel + 1)]), dRel, dRel)
  yTtl <- c(yTrain, yOOS)
  NNarray <- get.knnx(locsRelScal[1 : nTrain, , drop = F],
                      locsRelScal[(nTrain + 1) : (nTrain + nOOS), , drop = F], 
                      m)$nn.index
  NNarray <- cbind(NNarray, (nTrain + 1) : (nTrain + nOOS))
  mus <- rep(NA, nOOS)
  sds <- rep(NA, nOOS)
  for(i in 1 : nOOS){
    NN <- NNarray[i, ]
    K <- matern25_scaledim_sqrelevance(thetaRel, locsRel[NN, , drop = F])
    L <- t(chol(K))
    mus[i] <- L[m + 1, 1 : m] %*% 
      forwardsolve(L[1 : m, 1 : m], yTrain[NN[1 : m]])
    sds[i] <- L[m+1, m+1]
  }
  # sqrt(mean((yOOS - mus)^2))
  mean(crps_norm(y = yOOS, mean = mus, sd = sds))
}
```

Dataset name
```{r dataset name, eval = T}
datasetName <- "slice_localization_data"
```

## Analysis without fake predictors

Data construction
```{r reformat data, eval = T}
set.seed(123)
trainsetFn <- paste0(datasetName, "_train.csv")
testsetFn <- paste0(datasetName, "_test.csv")
datasetTrain <- read.table(file = trainsetFn, header = F, sep = ",",
                           row.names = NULL)
datasetTest <- read.table(file = testsetFn, header = F, sep = ",",
                          row.names = NULL)
# test
# datasetTrain <- read.table(file = trainsetFn, header = F, sep = ",",
#                            row.names = NULL)[1 : 10000, ]
nTrain <- nrow(datasetTrain)
nTest <- nrow(datasetTest)
nOOS <- min(5e3, floor(nTrain / 2))
d <- ncol(datasetTrain) - 1
idxOOS <- sample(1 : nTrain, nOOS, replace = F)
locsTrain <- as.matrix(datasetTrain[- idxOOS, 1 : d])
locsOOS <- as.matrix(datasetTrain[idxOOS, 1 : d])
locsTest <- as.matrix(datasetTest[, 1 : d])
nTrain <- nTrain - nOOS
# standardize y
yTrain <- datasetTrain[- idxOOS, d + 1]
yOOS <- datasetTrain[idxOOS, d + 1]
yTest <- datasetTest[, d + 1]
meanYTrain <- mean(yTrain)
sdYTrain <- sd(yTrain)
yTrain <- (yTrain - meanYTrain) / sdYTrain
yOOS <- (yOOS - meanYTrain) / sdYTrain
yTest <- (yTest - meanYTrain) / sdYTrain
rm(datasetTest, datasetTrain)
```

Some EDA for `y`
```{r EDA y, eval = F}
library(ggplot2)
hist(c(yTrain, yOOS, yTest))
```

## Using just mean
```{r compare with using just mean, eval = T}
var(yTest) * nrow(yTest)
```

## PCR
```{r pcr without fake, eval = F}
pcrMdl <- pcr(yTrain ~ locsTrain, ncomp = 20)
pcrPred <- predict(pcrMdl, locsTest, ncomp = 20)
sum((pcrPred - yTest)^2) * sdYTrain^2
rm(pcrMdl)
```

## Lasso regression.
```{r Lasso regression, eval = F}
library(glmnet)
lassoPath <- glmnet(x = locsTrain, y = yTrain,
                         alpha = 1, intercept = T)
plot(lassoPath)
lassoOOS <- matrix(lassoPath$a0, nrow = nOOS, 
                   ncol = ncol(lassoPath$beta), byrow = T) +
  locsOOS %*% lassoPath$beta
OOSRMSE <- apply(lassoOOS, MARGIN = 2, function(x){
  sum((x - yOOS)^2)
  })
OOSRMSEChg <- c(1, 1 - OOSRMSE[2 : length(OOSRMSE)] / 
                  OOSRMSE[1 : (length(OOSRMSE) - 1)])
idxOptLasso <- which(OOSRMSEChg < 1e-2)[1] - 1
lassoPred <- apply(locsTest, 1, 
                   function(x){sum(x * lassoPath$beta[, idxOptLasso]) +
                       lassoPath$a0[idxOptLasso]})
sum((lassoPred - yTest)^2) * sdYTrain^2
sum(lassoPath$beta[, idxOptLasso] > 0)
```

## VREG
```{r load VREG function, eval = T}
source("VREG.R")
set.seed(123)
VRegRslt <- VReg(m = 100, k = 5, outputFn = paste0(datasetName, "_VREG.RData"))
```

RMSE
```{r predict at testing locs with VREG, eval = T}
load(paste0(datasetName, "_VREG.RData"))
idxOpt <- max(length(thetaSet) - 1, 1)
m <- 100
fit <- list(y = yTrain, locs = locsTrain[, idxSet[[idxOpt]] - 1, drop = F], 
              covparms = thetaSet[[idxOpt]][c(1, idxSet[[idxOpt]], d + 2)], 
              X = matrix(0, nTrain, 1), 
              betahat = 0, covfun_name = "matern25_scaledim_sqrelevance", 
              trend = "zero")
predObj <- predictions_scaled(fit, locsTest[, idxSet[[idxOpt]] - 1, drop = F], 
                              m, T)
GPPredVREG <- predObj
cat("RMSE of VREG:", sum((GPPredVREG - yTest)^2) * sdYTrain^2, "\n")
```

## Forward Selection

```{r load FWD function, eval = F}
source("forward_selection.R")
set.seed(123)
fwdRslt <- forward_selection(m = 100, paste0(datasetName, "_FWD.RData"))
```

RMSE
```{r predict at testing locs with fwd, eval = F}
load(paste0(datasetName, "_FWD.RData"))
idxOpt <- max(length(thetaSet) - 1, 1)
m <- 100
fit <- list(y = yTrain, locs = locsTrain[, idxSet[[idxOpt]] - 1, drop = F], 
              covparms = thetaSet[[idxOpt]][c(1, idxSet[[idxOpt]], d + 2)], 
              X = matrix(0, nTrain, 1), 
              betahat = 0, covfun_name = "matern25_scaledim_sqrelevance", 
              trend = "zero")
predObj <- predictions_scaled(fit, locsTest[, idxSet[[idxOpt]] - 1, drop = F], 
                              m, T)
GPPredFWD <- predObj
cat("RMSE of FWD:", sum((GPPredFWD - yTest)^2) * sdYTrain^2, "\n")
```














































