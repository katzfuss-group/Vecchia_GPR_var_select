---
title: "simulation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

* Generate $10^5$ observations from a 3D grid, using `RandomFields`
* Generate fake predictors
* Estimate parameters for each `lambda`
* Time the estimation process
* Generate correlated true/fake predictors and repeat the above procedure

## Simulation

The simulation study.

```{r install the moderated GpGp Pkg}
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
library(mvtnorm)
library(lhs)
library(FNN)
library(RandomFields)
if(file.exists("CQCD.R")){
  source("CQCD.R")
}else{
  source("../CQCD.R")
}
set.seed(123)
```

Generate observations.
```{r gen obs}
RFoptions(spConform=FALSE)
set.seed(123)
var <- 1
tausq <- 0.05^2
r0 <- c(2, 1, 0.5)
loc1 <- seq(from = 0, to = 1, length.out = 100)
loc1 <- loc1 * 100 / sqrt(sum(loc1^2))
loc2 <- seq(from = 0, to = 1, length.out = 100)
loc2 <- loc2 * 100 / sqrt(sum(loc2^2))
loc3 <- seq(from = 0, to = 1, length.out = 10)
loc3 <- loc3 * 10 / sqrt(sum(loc3^2))
scale <- 1 / max(loc1, loc2, loc3)
model <- RMwhittle(var = var, scale = scale, nu = 2.5)
y <- RFsimulate(model, 
                x = loc1 * r0[1] * scale, 
                y = loc2 * r0[2] * scale,
                z = loc3 * r0[3] * scale,
                grid = T)
```

Define `d`, `k`, and `m`.
```{r d and m}
d <- 1e3
m <- 1e2
k <- 3
```

Build the independent predictors and `y`.
```{r indep predictors}
n <- length(y)
locsT <- matrix(NA, n, 3)
yTmp <- rep(NA, n)
for(i1 in 1 : 100)
  for(i2 in 1 : 100)
  {
    idx <- ((i1 - 1) * 1000 + (i2 - 1) * 10 + 1) : 
      ((i1 - 1) * 1000 + (i2 - 1) * 10 + 10) 
    locsT[idx, ] <- cbind(rep(loc1[i1], length(loc3)), 
                          rep(loc2[i2], length(loc3)), 
                          loc3)
    yTmp[idx] <- y[i1, i2, ]
  }
y <- yTmp
locsF <- randomLHS(n, d - 3)
locsF <- locsF * outer(rep(sqrt(n), n), 
                     1 / sqrt(colSums(locsF^2)))
locs <- cbind(locsT, locsF)
cat("Independent predictors generated \n")
```

Add noise and demean `y`.
```{r demean y}
y <- y + rnorm(n, 0, var * tausq)
y <- y - mean(y)
```

Set aside OOS dataset.
```{r OOS}
nOOS <- 5e3
idxOOS <- sample(1 : n, nOOS)
yOOS <- y[idxOOS]
locsOOS <- locs[idxOOS, , drop = F]
y <- y[-idxOOS]
locs <- locs[-idxOOS, , drop = F]
n <- n - nOOS
cat("Out of sample data separated\n")
```

Function for computing the OOS score.
```{r OOS score}
OOS_score <- function(theta)
{
  idxLocsRel <- which(theta[2 : (d + 1)] > 0)
  dRel <- length(idxLocsRel)
  locsRel <- rbind(locs, locsOOS)[, idxLocsRel, drop = F]
  thetaRel <- theta[c(1, idxLocsRel + 1, d + 2)]
  locsRelScal <- locsRel %*% 
    diag(sqrt(thetaRel[2 : (dRel + 1)]), dRel, dRel)
  yTtl <- c(y, yOOS)
  NNarray <- get.knnx(locsRelScal[(n + 1) : (n + nOOS), , drop = F], 
                      locsRelScal[1 : n, , drop = F], m)$nn.index
  NNarray <- cbind((n + 1) : (n + nOOS), NNarray)

  - vecchia_meanzero_loglik(thetaRel, "matern25_scaledim_sqrelevance",
                            yTtl, locsRel, NNarray)$loglik
}
```
Bridge penalty with `gamma = 1/4`.
```{r logistic penalty}
gamma <- 1/4
penfun <- function(theta){
  lambda * sum(theta[-c(1, length(theta))]^(gamma))
}
dpenfun <- function(theta){
  r <- theta[-c(1, length(theta))]
  rpen <- lambda * r^(gamma - 1) * gamma
  rpen[r < 1e-10] <- lambda * (1e-10)^(gamma - 1) * gamma
  c(0, rpen, 0)
}
ddpenfun <- function(theta){
  diag(rep(0, length(theta)))
}
```
Function for model fitting given lambda.
```{r fit model for lambda}
forward_backward <- function(theta0, idx0, gradObj0)
{
  theta <- theta0
  idx <- idx0
  gradObj <- gradObj0
  while(T)
  {
    odrDec <- order(gradObj$grad[2 : (d + 1)], decreasing = T)
    if(length(idx) == 0)
      idxNew <- 1 + odrDec[1 : k]
    else
      idxNew <- c(idx, 1 + setdiff(odrDec, idx - 1)[1 : k])
    idxSel <- setdiff(idxNew, idx)
    cat("Selected var:", idxSel, "\n")
    # opt with SR parameters
    thetaRel <- theta[c(1, idxNew, 2 + d)] 
    thetaRel[(length(idx) + 2) : (length(idx) + k + 1)] <- 1
    # maximin order and NNarray
    locsRel <- locs[, idxNew - 1, drop = F]
    locsRelScal <- locsRel %*% 
      diag(sqrt(thetaRel[2 : (1 + length(idxNew))]), 
           length(idxNew), length(idxNew))
    odr <- GpGp::order_maxmin(locsRelScal)
    yOdr <- y[odr]
    locsRelScalOdr <- locsRelScal[odr, , drop = F]
    locsOdr <- locs[odr, , drop = F]
    NNarray <- GpGp::find_ordered_nn(locsRelScalOdr, m = m)
    # extract relevant col in locsOdr and lb
    locsOdrRel <- locsOdr[, idxNew - 1, drop = F] 
    lbRel <- lb[c(1, idxNew, 2 + d)] 
    objfun <- function(theta, batchIdx){
      likObj <- GpGp::vecchia_meanzero_loglik(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, locsOdrRel, 
                                              NNarray[batchIdx, , drop = F])
      likObj$loglik <- likObj$loglik - penfun(theta)
      likObj
    }
    objfun_gdfm <- function(theta, batchIdx){
      likObj <- GpGp::vecchia_meanzero_loglik_grad_info(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, locsOdrRel, 
                                              NNarray[batchIdx, , drop = F])
      likObj$loglik <- likObj$loglik - penfun(theta)
      likObj$grad <- likObj$grad - dpenfun(theta)
      likObj$info <- likObj$info + ddpenfun(theta)
      likObj
    }
    optObj <- CQCD_stochastic(objfun, objfun_gdfm, n, 1e3, thetaRel, 
                              maxIterOut = 50, maxIterIn = 40, lb = lbRel,
                              arg_check = arg_check_SR)
    # Take out zero relevance
    thetaRel <- optObj$covparms
    idxLocZero <- which(thetaRel[2 : (1 + length(idxNew))] == 0)
    if(length(idxLocZero) > 0)
    {
      idxDesel <- idxNew[idxLocZero]
      cat("Predictor", idxDesel, "are zerod out \n")
      idxNew <- idxNew[-idxLocZero]
      thetaRel <- thetaRel[-(idxLocZero + 1)]
    }
    theta <- rep(0, length(theta))
    theta[c(1, idxNew, length(theta))] <- thetaRel
    idx <- idxNew
    # compute grad with thetaNew
    batchIdx <- sample(x = 1 : n, size = 5e3, replace = F)
    gradObj <- 
      GpGp::vecchia_meanzero_loglik_grad_info(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, locsOdr, 
                                              NNarray[batchIdx, , drop = F])
    # break condition
    if((length(idxLocZero) > 0 && any(idxSel %in% idxDesel)) || 
       length(idx) > 20)
      break
  }
  cat("lambda =", lambda, "idx =", idx, "\n\n")
  return(list(lambda = lambda, theta = theta, idx = idx, gradObj = gradObj))
}
```

Storage variabels for plotting later.
```{r lambda grid}
# define result collecting vars
idxSet <- list()
thetaSet <- list()
scoreSet <- list()
lambdaSet <- list()
loglikSet <- list()
```

Initialization.
```{r nitialization}
sigmasqInit <- 0.25
tausqInit <- 0.01
theta <- c(sigmasqInit, rep(1e-8, d), tausqInit)
lb <- c(0.01^2, rep(0, d), 0.01^2) 
arg_check_SR <- function(x) {sum(sqrt(x[-c(1, length(x))])) > 1e-4}
idx <- c()
yOdr <- y
locsOdr <- locs
NNarray <- find_ordered_nn(locs, m = m)
cat("NNarray init finished\n")
batchIdx <- sample(x = 1 : n, size = 5e3, replace = F)
gradObj <- vecchia_meanzero_loglik_grad_info(theta, 
                                            "matern25_scaledim_sqrelevance",
                                            yOdr, locsOdr, 
                                            NNarray[batchIdx, , drop = F])
cat("gradObj init for forward_backward selection finished\n")
```

Loop over lambda.
```{r loop over lambda}
lambdaVec <- rev(c(0, kronecker(10^(-1 : max(round(log10(n)) - 2, 1)), 
                                c(1, 2, 5))))
niter <- length(lambdaVec)
for(i in 1 : niter)
{
  cat("\n====================================\n")
  lambda = lambdaVec[i]
  cat("i =", i, "lambda =", lambda, "\n")
  # fit model with penalty
  optObj <- forward_backward(theta, idx, gradObj)
  theta <- optObj$theta
  idx <- optObj$idx
  gradObj <- optObj$gradObj
  # Store results
  idxSet[[i]] <- optObj$idx
  thetaSet[[i]] <- optObj$theta
  scoreSet[[i]] <- OOS_score(optObj$theta)
  lambdaSet[[i]] <- lambda
  loglikSet[[i]] <- optObj$gradObj$loglik
}
```

Store results.
```{r save the result}
save(list = c("d", "idxSet", "thetaSet", "scoreSet", "lambdaSet", "loglikSet",
              "lambdaVec", "n"), 
     file = paste0("simulation_", n + nOOS, "_", d, ".RData"))
```
















