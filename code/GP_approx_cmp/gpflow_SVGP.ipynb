{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b88bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from gpflow.ci_utils import *\n",
    "from gpflow.utilities import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7673c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c63400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adam(model, iterations):\n",
    "    \"\"\"\n",
    "    Utility function running the Adam optimizer\n",
    "\n",
    "    :param model: GPflow model\n",
    "    :param interations: number of iterations\n",
    "    \"\"\"\n",
    "    # Create an Adam Optimizer action\n",
    "    logf = []\n",
    "    training_loss = model.training_loss_closure(tensor_data, compile=True)\n",
    "    optimizer = tf.optimizers.Adam()\n",
    "\n",
    "    @tf.function\n",
    "    def optimization_step():\n",
    "        optimizer.minimize(training_loss, model.trainable_variables)\n",
    "\n",
    "    for step in range(iterations):\n",
    "        optimization_step()\n",
    "        if step % 10 == 0:\n",
    "            elbo = -training_loss().numpy()\n",
    "            logf.append(elbo)\n",
    "    return logf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750619e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 12:56:30.737163: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;__main__.Matern25_aniso object at 0x167e21190&gt;\n",
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                       </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Matern25_aniso.variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>1.0              </td></tr>\n",
       "<tr><td>Matern25_aniso.lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>(10,)  </td><td>float64</td><td>[20., 20., 0.2...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<__main__.Matern25_aniso object at 0x167e21190>\n",
       "╒═════════════════════════════╤═══════════╤═════════════╤═════════╤═════════════╤═════════╤═════════╤═══════════════════╕\n",
       "│ name                        │ class     │ transform   │ prior   │ trainable   │ shape   │ dtype   │ value             │\n",
       "╞═════════════════════════════╪═══════════╪═════════════╪═════════╪═════════════╪═════════╪═════════╪═══════════════════╡\n",
       "│ Matern25_aniso.variance     │ Parameter │ Softplus    │         │ True        │ ()      │ float64 │ 1.0               │\n",
       "├─────────────────────────────┼───────────┼─────────────┼─────────┼─────────────┼─────────┼─────────┼───────────────────┤\n",
       "│ Matern25_aniso.lengthscales │ Parameter │ Softplus    │         │ True        │ (10,)   │ float64 │ [20., 20., 0.2... │\n",
       "╘═════════════════════════════╧═══════════╧═════════════╧═════════╧═════════════╧═════════╧═════════╧═══════════════════╛"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 10\n",
    "class Matern25_aniso(gpflow.kernels.AnisotropicStationary):\n",
    "     def K_d(self, d):\n",
    "            sqrt5 = np.sqrt(5.0)\n",
    "            d = tf.square(d)\n",
    "            d = tf.reduce_sum(d, -1)\n",
    "            d = tf.sqrt(d)\n",
    "            return self.variance * (1.0 + sqrt5 * d + 5.0 / 3.0 * tf.square(d)) * tf.exp(-sqrt5 * d)\n",
    "Matern25_aniso(variance = 1.0, lengthscales = np.concatenate([np.repeat(20, 2), np.repeat(0.2, d - 2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18502424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 12:56:30.844352: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-10-15 12:56:34.507252: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "mMax = 52\n",
    "for i in range(1, 11):\n",
    "    with open(\"locs_\" + str(i) + \".csv\") as locsFile:\n",
    "        locs = np.genfromtxt(locsFile, delimiter = ',').reshape((-1, d))\n",
    "        locsInduce = locs[ : mMax, :]\n",
    "        locs = locs[mMax :, :]\n",
    "        y = np.zeros((locs.shape[0], 1))\n",
    "        for M in range(4, 53, 4): # Number of inducing locations  \n",
    "            data = (locs, y)\n",
    "            kernel = Matern25_aniso(variance = 1.0, \n",
    "                                    lengthscales = np.concatenate([np.repeat(20, 2), np.repeat(0.2, d - 2)]))\n",
    "            Z = locsInduce[: M, :].copy()  # Initialize inducing locations to the first M inputs in the dataset\n",
    "            m = gpflow.models.SVGP(kernel, gpflow.likelihoods.Gaussian(), Z, num_data = y.size, mean_function=None)\n",
    "            gpflow.set_trainable(m.kernel, False)\n",
    "            gpflow.set_trainable(m.inducing_variable, True)\n",
    "            tensor_data = tuple(map(tf.convert_to_tensor, data))\n",
    "            maxiter = ci_niter(1000)\n",
    "            run_adam(m, maxiter)\n",
    "            np.savetxt(\"induce_\" + str(i) + \"_\" + str(M) + \".csv\",\n",
    "                       np.array(m.inducing_variable.parameters[0]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be93f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
