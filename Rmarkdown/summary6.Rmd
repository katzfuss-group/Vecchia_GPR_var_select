---
title: "summary6"
author: "Jian Cao"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

In this markdown, I will try optimization with: 

* $d = 1000$ 
* the relevance parameter
* use a batch size of 1 and optimization iteration of 1
* no penalty

## Preparation
Need to install a modified version of the `GpGp` R package.
```{r install the moderated GpGp Pkg}
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
Sys.setenv(OMP_NUM_THREADS = 8)
```
Need to load the `quad_cdsc_L1` and the `batch_start` functions.
```{r load relevant function}
source("quad_cdsc_L1.R")
source("batch_start.R")
```

## Simulate GP in $\mathbb{R}^{1000}$
```{r simulate GP in d dimensions}
set.seed(123)
n <- 1e4
d <- 1e2
r <- c(10, 5, 2, 1, 0.5, rep(0, d - 5))
sigmasq <- 1.0 # variance
tausq <- 0.05^2 # nugget
locs <- lhs::randomLHS(n, d)
locs <- locs * outer(rep(sqrt(n), n), 1 / sqrt(colSums(locs^2)))
covM <- GpGp::matern25_scaledim_relevance(c(sigmasq, r, tausq), locs)
cholM <- t(chol(covM))
y <- as.vector(cholM %*% rnorm(n))
X <- matrix(1, n, 1)
rm(covM, cholM)
```
Notice that we still have only 5 non-zero relevance parameters but at the last five positions. Define the conditioning size `m`.
```{r conditioning size}
m <- 100
```

## Optimization 
Define initial values for non-relevance parameters.
```{r init val for non-rel parms-penalty parms-opt bounds}
sigmasqInit <- 0.25
tausqInit <- 0.01^2
lb_nonrel_parms <- c(0.01^2, 0.01^2) 
```
`lb_nonrel_parms` defines the lower limit of $\sigma^2$ and $\tau^2$ during the optimization using `quad_cdsc_L1`. `opt_func_wrapper` is a wrapper of the `quad_cdsc_L1` function.
```{r funcs for batch_start and cross-valid}
opt_func_wrapper <- function(X, ...) {
  quad_cdsc_L1(start_parms = X, ...)
}
```
Do `batch_start` with `lambda = 0` for two times. 
```{r two times batch_start}
startTime <- Sys.time()

theta <- c(sigmasqInit, rep(1, d), tausqInit) # used for initial ordering of locs
for(i in 1 : 2)
{
  if(all(theta[2 : (d + 1)] == 0))
    stop("All range parameters are zero. Cannot perform reordering\n")
  locsScal <- locs %*% diag(theta[2 : (d + 1)])
  odr <- GpGp::order_maxmin(locsScal)
  yOdr <- y[odr]
  locsScalOdr <- locsScal[odr, , drop = F]
  locsOdr <- locs[odr, , drop = F]
  XOdr <- X[odr, , drop = F]
  NNarray <- GpGp::find_ordered_nn(locsScalOdr, m = m)
  
  objfun <- function(theta, locs){
    GpGp::vecchia_profbeta_loglik(theta, "matern25_scaledim_relevance",
                                  yOdr, XOdr, locs, NNarray)
  }
  objfun_gdfm <- function(theta, locs){
    GpGp::vecchia_profbeta_loglik_grad_info(theta, "matern25_scaledim_relevance",
                                            yOdr, XOdr, locs, NNarray)
  }
  
  optObj <- batch_start(nonrel_parms = theta[-c(2 : (d + 1))], d = d, batch_sz = 1, 
              extra_batch = 0, opt_fun = opt_func_wrapper, 
              rel_parms = rep(0, d), likfun = objfun, 
              likfunGDFIM = objfun_gdfm, locs = locsOdr, p = 1, lambda = 0, 
              epsl = 1e-3, silent = T, max_iter = 1, lb_nonrel_parms = lb_nonrel_parms)
  theta <- optObj$covparms
}

endTime <- Sys.time()
cat("Two times of fitting without penalty used", 
    as.numeric(difftime(endTime, startTime, units = "secs")), "seconds\n")
```
See which indices of `theta` are greater than zero and what are their values.
```{r check first round fitting}
which(theta > 0)
theta[theta > 0]
```
Now I downsize `locs` to make the cross validation much faster. 
```{r downsizing locs}
idxLocsZero <- theta[2 : (d + 1)] == 0
theta <- theta[c(T, theta[2 : (d + 1)] > 0, T)]
locs <- locs[, !idxLocsZero]
d <- d - sum(idxLocsZero)
```
The final fit inherits the previously computed `theta` without penalty. 
```{r}
startTime <- Sys.time()
crtIter <- 1
maxIter <- 100
while(maxIter >= crtIter)
{
  locsScal <- locs %*% diag(theta[2 : (d + 1)])
  odr <- GpGp::order_maxmin(locsScal)
  yOdr <- y[odr]
  locsScalOdr <- locsScal[odr, , drop = F]
  locsOdr <- locs[odr, , drop = F]
  XOdr <- X[odr, , drop = F]
  NNarray <- GpGp::find_ordered_nn(locsScalOdr, m = m)
  # Define functions for parameter estimation in the outer loop
  objfun <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik(theta, "matern25_scaledim_relevance",
                                            yOdr, XOdr, locsOdr, 
                                            NNarray)
  }
  objfun_gdfm <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik_grad_info(theta, "matern25_scaledim_relevance",
                                            yOdr, XOdr, locsOdr, 
                                            NNarray)
  }
  
  theta <- quad_cdsc_L1(objfun, objfun_gdfm, locsOdr, 1, theta, 0, 1e-3, silent = T, 
               max_iter = min(crtIter, maxIter - crtIter + 1), max_iter2 = 40, 
               lb_nonrel_parms = lb_nonrel_parms)$covparms
  cat("quad_cdsc_L1 fit iter", crtIter, ": estimated parms = ", theta, "\n")
  crtIter <- crtIter + min(crtIter, maxIter - crtIter + 1)
}
endTime <- Sys.time()
cat("Final estimates are", theta, "\n")
cat("Time used for final estimation is", as.numeric(difftime(endTime, startTime, units = "secs")), "seconds\n")
```










