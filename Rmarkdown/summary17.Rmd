---
title: "summary17"
author: "Jian Cao"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
This summary produces a plot supporting that gradients w.r.t. SRs are informative, i.e., showing which covariates are more likely to be true.

## Preparation
Need to install a modified version of the GpGp R package.
```{r install the moderated GpGp Pkg}
rm(list = ls())
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
library(mvtnorm)
source("quad_cdsc_L1.R")
set.seed(123)
```

## Stopping condition
```{r stopping condition}
stop_cond <- function(objOld, objNew, dOld, dNew)
{
  BICOld <- log(n) * dOld + 2 * objOld
  BICNew <- log(n) * dNew + 2 * objNew
  return(BICNew > BICOld)
} 
```

## Experiment
```{r exp with d equal to 1e3}
n <- 1e4
d <- 20
m <- 100
k <- 1
rSq <- c(1, 1, 1, 1, 1, rep(0, d - 5))^2
sigmasq <- 1.0 # variance
tausq <- 0.05^2 # nugget
locs <- lhs::randomLHS(n, d)
locs <- locs * outer(rep(sqrt(n), n), 1 / sqrt(colSums(locs^2)))
covM <- GpGp::matern25_scaledim_sqrelevance(c(sigmasq, rSq, tausq), locs)
cholM <- t(chol(covM))
y <- as.vector(cholM %*% rnorm(n))
X <- matrix(1, n, 1)
rm(covM, cholM)

sigmasqInit <- 0.25
tausqInit <- 0.01^2
lb_nonrel_parms <- c(0.01^2, 0.01^2) 
theta <- c(sigmasqInit, rep(1e-8, d), tausqInit)
idx <- c()
objOld <- Inf
rslt <- list()
startTime <- Sys.time()
for(i in 1 : 10)
{
  startTimeNNarrray <- Sys.time()
  idxLocs <- theta[2 : (d + 1)] > 0
  locsRel <- locs[, idxLocs, drop = F]
  locsScal <- locsRel %*% diag(sqrt(theta[2 : (d + 1)][idxLocs]), sum(idxLocs), sum(idxLocs))
  odr <- GpGp::order_maxmin(locsScal)
  yOdr <- y[odr]
  locsScalOdr <- locsScal[odr, , drop = F]
  locsOdr <- locs[odr, , drop = F]
  XOdr <- X[odr, , drop = F]
  NNarray <- GpGp::find_ordered_nn(locsScalOdr, m = m)
  endTimeNNarrray <- Sys.time()
  cat("Finding NNarray used", 
      as.numeric(difftime(endTimeNNarrray, startTimeNNarrray, units = "secs")), 
      "seconds\n")
  startTimeGrad <- Sys.time()
  gradObj <- GpGp::vecchia_profbeta_loglik_grad_info(theta, 
                                                     "matern25_scaledim_sqrelevance", yOdr, 
                                                     XOdr, locsOdr, NNarray)
  endTimeGrad <- Sys.time()
  cat("Computing gradient used", 
      as.numeric(difftime(endTimeGrad, startTimeGrad, units = "secs")), 
      "seconds\n")
  # select covariates
  if(length(idx) == 0)
  {
    idxNew <- 1 + order(gradObj$grad[2 : (d + 1)], decreasing = T)[1 : k]
    rslt[[3 * (i - 1) + 1]] <- gradObj$grad[2 : (d + 1)]
    rslt[[3 * (i - 1) + 2]] <- idx - 1
    rslt[[3 * (i - 1) + 3]] <-
      order(gradObj$grad[2 : (d + 1)], decreasing = T)[1 : k]
  }else
  {
    odrDec <- order(gradObj$grad[2 : (d + 1)], decreasing = T)
    idxNew <- c(idx, 1 + setdiff(odrDec, idx - 1)[1 : k])
    rslt[[3 * (i - 1) + 1]] <- gradObj$grad[2 : (d + 1)]
    rslt[[3 * (i - 1) + 2]] <- idx - 1
    rslt[[3 * (i - 1) + 3]] <-
      order(gradObj$grad[2 : (d + 1)], decreasing = T)[1 : k]
  }
  cat(idxNew, "\n")
  
  thetaTmp <- theta[c(1, idxNew, 2 + d)]
  locsOdr <- locsOdr[, idxNew - 1, drop = F]
  
  # opt with SR parameters
  objfun <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik(theta, "matern25_scaledim_sqrelevance",
                                            yOdr, XOdr, locsOdr, 
                                            NNarray)
  }
  objfun_gdfm <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik_grad_info(theta, "matern25_scaledim_sqrelevance",
                                            yOdr, XOdr, locsOdr, 
                                            NNarray)
  }
  startTimeOpt1 <- Sys.time()
  optObj <- quad_cdsc_L1_brute(objfun, objfun_gdfm, locsOdr, 1, thetaTmp, 0, 1e-3, silent = T, 
               max_iter = 10, max_iter2 = 100, 
               lb_nonrel_parms = lb_nonrel_parms)
  endTimeOpt1 <- Sys.time()
  cat("Opt with SR used", 
      as.numeric(difftime(endTimeOpt1, startTimeOpt1, units = "secs")), 
      "seconds\n")
  thetaTmp <- optObj$covparms
  cat(thetaTmp, "\n")
  
  # opt with relevance parameters
  thetaTmp[2 : (1 + length(idxNew))] <- sqrt(thetaTmp[2 : (1 + length(idxNew))])
  objfun <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik(theta, "matern25_scaledim_relevance",
                                            yOdr, XOdr, locsOdr,
                                            NNarray)
  }
  objfun_gdfm <- function(theta, locsOdr){
    GpGp::vecchia_profbeta_loglik_grad_info(theta, "matern25_scaledim_relevance",
                                            yOdr, XOdr, locsOdr,
                                            NNarray)
  }
  startTimeOpt2 <- Sys.time()
  optObj <- quad_cdsc_L1(objfun, objfun_gdfm, locsOdr, 1, thetaTmp, 0, 1e-3, silent = T,
               max_iter = 20, max_iter2 = 100,
               lb_nonrel_parms = lb_nonrel_parms)
  endTimeOpt2 <- Sys.time()
  cat("Opt with rel used", 
      as.numeric(difftime(endTimeOpt2, startTimeOpt2, units = "secs")), 
      "seconds\n")
  thetaTmp <- optObj$covparms
  thetaTmp[2 : (1 + length(idxNew))] <- thetaTmp[2 : (1 + length(idxNew))]^2
  cat(thetaTmp, "\n")
  objNew <- optObj$obj
  # if(stop_cond(objOld, objNew, length(idx), length(idxNew)))
  #   break;
  
  idx <- idxNew
  objOld <- objNew
  theta <- rep(0, d + 2)
  theta[c(1, idx, d + 2)] <- thetaTmp
}
cat(idx, "\n")
cat(theta[c(1, idx, d + 2)], "\n")
endTime <- Sys.time()
cat("Time used for estimation is", as.numeric(difftime(endTime, startTime, units = "secs")), "seconds\n")
```
## Plot the results
```{r}
mydf <- matrix(NA, d * 10, 4)
for(i in 1 : 10)
{
  mydf[((i - 1) * d + 1) : (i * d), 1] <- rslt[[3 * (i - 1) + 1]]
  mydf[((i - 1) * d + 1) : (i * d), 2] <- i
  mydf[((i - 1) * d + 1) : (i * d), 4] <- 1 # color
  mydf[(i - 1) * d + which(rslt[[3 * (i - 1) + 1]] < 0), 4] <- 3 # color
  mydf[(i - 1) * d + setdiff(rslt[[3 * (i - 1) + 2]], rslt[[3 * i]]), 1 : 2] <- 
    NA
  mydf[(i - 1) * d + rslt[[3 * i]], 3] <- rslt[[3 * i]]
  mydf[(i - 1) * d + rslt[[3 * i]], 4] <- 2 # color
}
mydf <- as.data.frame(mydf)
colnames(mydf) <- c("gradient", "iter", "label", "color")
mydf <- mydf[!is.na(mydf$gradient), ]
mydf$iter <- as.factor(mydf$iter)
mydf$gradient <- abs(mydf$gradient)
mydf$color[mydf$color == 2] <- "selected var"
mydf$color[mydf$color == 1] <- "positive grads"
mydf$color[mydf$color == 3] <- "negative grads"
```

```{r}
library(ggplot2)
library(RColorBrewer)
library(scales)
ggplot(data = mydf, aes(x = iter, y = gradient, col = factor(color),
                        label = label)) +
  geom_text(nudge_x = 0.4, show.legend = FALSE) +
  geom_point() +
  scale_color_brewer(palette="Dark2") +
  scale_y_continuous(trans = "log2",
                     labels = trans_format('log2',math_format(2^.x))) +
  xlab("iteration number") +
  # scale_x_discrete(limits = c("1", "11")) + 
  theme(legend.title = element_blank(), legend.position="right") +
  expand_limits(x = c(11))
ggsave("gradient_sr.pdf", width = 6, height = 3.375)
```





