---
title: "stepk_indep_pen_inv_sr"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
This summary uses the inverse penalty with `lambda` in `lambdaVec`. The step size can be defined in `k`. Hopefully, this is less arbitrary than simply using the BIC criterion. Now the model choosing criterion is the LOO log-score. Penalty is added to squared relevance parameters. Relevance parameters are not used.
```{r clean environment}
rm(list = ls())
```


## Preparation
Need to install a modified version of the GpGp R package.
```{r install the moderated GpGp Pkg}
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
library(mvtnorm)
library(ggplot2)
library(RColorBrewer)
library(scales)
library(FNN)
source("CQCD.R")
set.seed(123)
```

## Experiment
Simulate GP.
```{r simulate GP}
n <- 1e4
d <- 100
m <- 100
k <- 3
rSq <- c(10, 5, 2, 1, 0.5, rep(0, d - 5))^2
sigmasq <- 1.0 # variance
tausq <- 0.05^2 # nugget
locs <- lhs::randomLHS(n, d)
locs <- locs * outer(rep(sqrt(n), n), 
                     1 / sqrt(colSums(locs^2)))
covM <- GpGp::matern25_scaledim_sqrelevance(c(sigmasq, rSq, tausq), locs)
cholM <- t(chol(covM))
y <- as.vector(cholM %*% rnorm(n))
X <- matrix(1, n, 1)
rm(covM, cholM)
```
Function for computing the approximate LOO-CV score, assuming the squared relevance parameterized Matern25 kernel.
```{r LOO-CV score}
CV_score <- function(theta)
{
  idxLocsRel <- which(theta[2 : (d + 1)] > 0)
  locsRel <- locs[, idxLocsRel, drop = F]
  thetaRel <- theta[c(1, idxLocsRel + 1, d + 2)]
  dRel <- length(idxLocsRel)
  locsRelScal <- locsRel %*% 
    diag(sqrt(thetaRel[2 : (dRel + 1)]), dRel, dRel)
  NNarray <- get.knnx(locsRelScal, locsRelScal, m + 1)$nn.index
  - vecchia_profbeta_loglik(thetaRel, "matern25_scaledim_sqrelevance",
                            y, X, locsRel, NNarray)$loglik
}
```
Grid for the penalty `lambda`.
```{r lambda grid}
lambdaVec <- c(exp(seq(from = log(4e12), to = 0, length.out = 15)),
               seq(from = 0.9, to = 0, length.out = 5))
# define result collecting vars
idxSet <- list()
thetaSet <- list()
scoreSet <- list()
```
Fit model for each `lambda`.
```{r forward-backward selection}
sigmasqInit <- 0.25
tausqInit <- 0.01^2
theta <- c(sigmasqInit, rep(1e-8, d), tausqInit)
lb <- c(0.01^2, rep(0, d), 0.01^2) 
arg_check_SR <- function(x) {sum(sqrt(x[-c(1, length(x))])) > 1e-4}
arg_check_R <- function(x) {sum(x[-c(1, length(x))]) > 1e-4}
idx <- c()
scorePrev <- Inf
loglkPen <- - Inf 
SRFlag <- T
XOdr <- X
yOdr <- y
locsOdr <- locs
NNarray <- find_ordered_nn(locs, m = m)
startTime <- Sys.time()
for(i in 1 : length(lambdaVec))
{
  lambda <- lambdaVec[i]
  if(exists("lambdaPrev"))
    loglkPen <- loglkPen - (lambda - lambdaPrev) * sum(theta[2 : (d + 1)] > 0)
  while(TRUE)
  {
    if(SRFlag)
    {
      # compute grad for all predictors
      startTimeGrad <- Sys.time()
      gradObj <- 
        vecchia_profbeta_loglik_grad_info(theta, 
                                          "matern25_scaledim_sqrelevance",
                                          yOdr, XOdr, locsOdr, NNarray)
      endTimeGrad <- Sys.time()
      cat("Computing gradient used", 
          as.numeric(difftime(endTimeGrad, startTimeGrad, units = "secs")), 
          "seconds\n")
      # select covariates
      odrDec <- order(gradObj$grad[2 : (d + 1)], decreasing = T)
      if(length(idx) == 0)
        idxNew <- 1 + odrDec[1 : k]
      else
        idxNew <- c(idx, 1 + setdiff(odrDec, idx - 1)[1 : k])
      cat("\nlambda = ", lambda, ": selected var", setdiff(idxNew, idx), "\n")
      # remove irrelevant predictors
      thetaRel <- theta[c(1, idxNew, 2 + d)] 
      locsOdrRel <- locsOdr[, idxNew - 1, drop = F] 
      lbRel <- lb[c(1, idxNew, 2 + d)] 
      # opt with SR parameters without penalty
      objfun <- function(theta){
        GpGp::vecchia_profbeta_loglik(theta, "matern25_scaledim_sqrelevance",
                                                yOdr, XOdr, locsOdrRel, 
                                                NNarray)
      }
      objfun_gdfm <- function(theta){
        GpGp::vecchia_profbeta_loglik_grad_info(theta, 
                                                "matern25_scaledim_sqrelevance",
                                                yOdr, XOdr, locsOdrRel, 
                                                NNarray)
      }
      startTimeOpt1 <- Sys.time()
      optObj <- CQCD(objfun, objfun_gdfm, thetaRel, maxIterOut = 3, 
                     maxIterIn = 40, lb = lbRel, arg_check = arg_check_SR)
      endTimeOpt1 <- Sys.time()
      cat("Opt with SR (no penalty) used", 
          as.numeric(difftime(endTimeOpt1, startTimeOpt1, units = "secs")), 
          "seconds\n")
      thetaRel <- optObj$covparms
      thetaRelTmp <- thetaRel
    }else
    {
      cat("\nlambda = ", lambda, ": loglkPen = ", loglkPen, ", selected var:", 
          setdiff(idxNew, idx), "\n")
      thetaRel <- thetaRelTmp
      SRFlag <- T
    }
    # opt with SR parameters, here BIC penalty is applied
    dRel <- length(idxNew)
    BIC_pen <- function(theta){
      idx <- which(thetaRel[2 : (1 + dRel)] > 0) + 1
      sum(pmin(theta[idx] / (thetaRel[idx]), 1)) * lambda
    }
    BIC_dpen <- function(theta){
      idx <- which(thetaRel[2 : (1 + dRel)] > 0) + 1
      dpen <- rep(0, length(theta))
      dpen[idx] <- (theta[idx] <= thetaRel[idx]) / 
        (thetaRel[idx]) * lambda
      dpen
    }
    objfun <- function(theta){
      likObj <- GpGp::vecchia_profbeta_loglik(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, XOdr, locsOdrRel,
                                              NNarray)
      likObj$loglik <- likObj$loglik - BIC_pen(theta)
      likObj
    }
    objfun_gdfm <- function(theta){
      likObj <- 
        GpGp::vecchia_profbeta_loglik_grad_info(theta,
                                                "matern25_scaledim_sqrelevance",
                                                yOdr, XOdr, locsOdrRel, NNarray)
      likObj$loglik <- likObj$loglik - BIC_pen(theta)
      likObj$grad <- likObj$grad - BIC_dpen(theta)
      likObj
    }
    startTimeOpt2 <- Sys.time()
    optObj <- CQCD(objfun, objfun_gdfm, thetaRel, maxIterOut = 20, 
                   maxIterIn = 40,
                   lb = lbRel, arg_check = arg_check_R, convtolOut = 1e-2)
    endTimeOpt2 <- Sys.time()
    cat("Opt with SR (with penalty) used", 
        as.numeric(difftime(endTimeOpt2, startTimeOpt2, units = "secs")), 
        "seconds\n")
    
    # order and compute loglkPen
    thetaRel <- optObj$covparms
    locsRel <- locs[, idxNew - 1, drop = F]
    locsRelScal <- locsRel %*% diag(sqrt(thetaRel[2 : (length(idxNew) + 1)]), 
                                 length(idxNew), length(idxNew))
    odrNew <- order_maxmin(locsRelScal)
    yOdrNew <- y[odrNew]
    locsRelScalOdrNew <- locsRelScal[odrNew, , drop = F]
    XOdrNew <- X[odrNew, , drop = F]
    locsRelOdrNew <- locsRel[odrNew, , drop = F]
    NNarrayNew <- find_ordered_nn(locsRelScalOdrNew, m = m)
    loglkPenNew <- GpGp::vecchia_profbeta_loglik(thetaRel, 
                                                 "matern25_scaledim_sqrelevance",
                                                 yOdrNew, XOdrNew, locsRelOdrNew,
                                                 NNarrayNew)$loglik - 
      lambda * sum(thetaRel[2 : (length(idxNew) + 1)] > 0)
    # if penalized log-lk not improving much
    if(is.finite(loglkPen) &&
       (loglkPenNew - loglkPen) / abs(loglkPen) < 1e-4) 
    {
      cat("\nlambda = ", lambda, ": stopped with:\nidx = ", idx, "\n",
          "theta = ", theta[c(1, idx, d + 2)], "\n",
          "loglkPen = ", loglkPen, ", loglkPenNew = ", loglkPenNew, "\n\n")
      break
    }
    # Take out zero relevance
    idxLocZero <- which(thetaRel[2 : (1 + length(idxNew))] == 0)
    if(length(idxLocZero) > 0)
    {
      cat("Predictor", idxNew[idxLocZero], "are zerod out \n")
      idxNew <- idxNew[-idxLocZero]
      thetaRel <- thetaRel[-(idxLocZero + 1)]
    }
    # Copy val for next iter
    idx <- idxNew
    theta <- rep(0, d + 2)
    theta[c(1, idx, d + 2)] <- thetaRel
    loglkPen <- loglkPenNew
    XOdr <- XOdrNew
    yOdr <- yOdrNew
    locsOdr <- locs[odrNew, , drop = F]
    NNarray <- NNarrayNew
  }
  # compute LOO-CV score, smaller is better
  score <- CV_score(theta)
  # record results
  idxSet[[i]] <- idx
  thetaSet[[i]] <- theta
  scoreSet[[i]] <- score
  # check if score is improving
  # if(exists("idxPrev") && length(idxPrev) > 2 && score > scorePrev)
  # {
  #   cat("\n")
  #   cat("Best lambda: ", lambdaPrev, "\n")
  #   cat("idx: ", idxPrev, "\n")
  #   cat("theta: ", thetaPrev, "\n")
  #   break # idxPrev, thetaPrev are better
  # }
  # cat("lambda = ", lambda, ": score = ", score, ", LOO-CV score improving\n")
  cat("lambda = ", lambda, ": score = ", score, "\n\n")
  scorePrev <- score
  lambdaPrev <- lambda
  idxPrev <- idx
  thetaPrev <- theta
  SRFlag <- F
}
```

```{r save the result}
save.image(file = paste0("step", k, "_indep_pen_inv_sr.RData"))
```
