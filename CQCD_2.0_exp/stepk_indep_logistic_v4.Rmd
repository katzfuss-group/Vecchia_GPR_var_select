---
title: "SR with Logistic Penalty V4.0"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Method 
Here, we ignore warm start, simply fit a model till convergence for each $\lambda$.


The pseudo-algorithm is:

* Initialize $\theta_0$, `maxminOrder`, `NNarray`
* $\theta = \theta_0$
* For `i` in `1 : niter`
  * Compute `grad` w.r.t. all parameters at $\theta$
  * $\lambda_0 = \mbox{max}(\nabla l(\theta)[\theta == 0], 0)$
  * $c = 1.0$
  * While($c$ has not been tried)
    * $\hat{\theta} = \mbox{fit model}(\lambda = c\lambda_0, \theta = \theta_0)$
    * If(Non-zero relevance in $\hat{\theta}$ < i)
      * $c = max(c - 0.1, 0)$
    * Else If(Non-zero relevance in $\hat{\theta}$ > i)
      * $c = c + 0.1$
    * Else
      * break
  * $\theta = \hat{\theta}$, store the tuple $(\lambda, \theta, \mbox{loglk}(\theta), \mbox{LOO-CV}(\theta))$

## Experiment
Clean the environment
```{r clean environment}
rm(list = ls())
```
Need to install a modified version of the GpGp R package.
```{r install the moderated GpGp Pkg}
devtools::install_github("https://github.com/SamCao1991/GpGp.git")
library(GpGp)
library(mvtnorm)
library(ggplot2)
library(RColorBrewer)
library(scales)
library(FNN)
source("CQCD.R")
set.seed(123)
```
Simulate GP.
```{r simulate GP, eval = T}
n <- 1e3
d <- 20
m <- 100
k <- 3
rSq <- c(10, 5, 2, 1, 0.5, rep(0, d - 5))^2
sigmasq <- 1.0 # variance
tausq <- 0.05^2 # nugget
locs <- lhs::randomLHS(n, d)
locs <- locs * outer(rep(sqrt(n), n), 
                     1 / sqrt(colSums(locs^2)))
covM <- GpGp::matern25_scaledim_sqrelevance(c(sigmasq, rSq, tausq), locs)
cholM <- t(chol(covM))
y <- as.vector(cholM %*% rnorm(n))
X <- matrix(1, n, 1)
rm(covM, cholM)
```
Function for computing the approximate LOO-CV score, assuming the squared relevance parameterized Matern25 kernel.
```{r LOO-CV score, eval = T}
CV_score <- function(theta)
{
  idxLocsRel <- which(theta[2 : (d + 1)] > 0)
  locsRel <- locs[, idxLocsRel, drop = F]
  thetaRel <- theta[c(1, idxLocsRel + 1, d + 2)]
  dRel <- length(idxLocsRel)
  locsRelScal <- locsRel %*% 
    diag(sqrt(thetaRel[2 : (dRel + 1)]), dRel, dRel)
  NNarray <- get.knnx(locsRelScal, locsRelScal, m + 1)$nn.index
  - vecchia_profbeta_loglik(thetaRel, "matern25_scaledim_sqrelevance",
                            y, X, locsRel, NNarray)$loglik
}
```
Logistic penalty functions.
```{r logistic penalty, eval = T}
penfun <- function(theta){
  r <- theta[-c(1, length(theta))]
  rExp <- exp(- r)
  sum(lambda / (1 + rExp) - lambda / 2)
}
dpenfun <- function(theta){
  r <- theta[-c(1, length(theta))]
  rExp <- exp(- r)
  c(0, lambda * rExp / (1 + rExp)^2, 0)
}
ddpenfun <- function(theta){
  # r <- theta[-c(1, length(theta))]
  # rExp <- exp(- r)
  # diag(c(0, lambda * (rExp^2 - rExp) / (1 + rExp)^3, 0))
  diag(rep(0, length(theta)))
}
```

Function for model fitting given lambda.
```{r fit model for lambda, eval = T}
fit_order_select_SR <- function(lambda)
{
  theta <- theta0
  loglkPen <- - Inf
  idx <- c()
  while(T)
  {
    # maximin order and NNarray
    idxLocRel <- theta[2 : (d + 1)] > 0
    locsRel <- locs[, idxLocRel, drop = F]
    locsRelScal <- locsRel %*% diag(sqrt(theta[2 : (d + 1)][idxLocRel]), 
                                 sum(idxLocRel), sum(idxLocRel))
    odr <- GpGp::order_maxmin(locsRelScal)
    yOdr <- y[odr]
    locsRelScalOdr <- locsRelScal[odr, , drop = F]
    locsOdr <- locs[odr, , drop = F]
    XOdr <- X[odr, , drop = F]
    NNarray <- GpGp::find_ordered_nn(locsRelScalOdr, m = m)
    # select k new predictors
    gradObj <- 
      GpGp::vecchia_profbeta_loglik_grad_info(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, XOdr, locsOdr, NNarray)
    odrDec <- order(gradObj$grad[2 : (d + 1)], decreasing = T)
    if(length(idx) == 0)
      idxNew <- 1 + odrDec[1 : k]
    else
      idxNew <- c(idx, 1 + setdiff(odrDec, idx - 1)[1 : k])
    cat("Selected var:", setdiff(idxNew, idx), "\n")
    # opt with SR parameters
    thetaRel <- theta[c(1, idxNew, 2 + d)] 
    locsOdrRel <- locsOdr[, idxNew - 1, drop = F] 
    lbRel <- lb[c(1, idxNew, 2 + d)] 
    objfun <- function(theta){
      likObj <- GpGp::vecchia_profbeta_loglik(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, XOdr, locsOdrRel, 
                                              NNarray)
      likObj$loglik <- likObj$loglik - penfun(theta)
      likObj
    }
    objfun_gdfm <- function(theta){
      likObj <- GpGp::vecchia_profbeta_loglik_grad_info(theta, 
                                              "matern25_scaledim_sqrelevance",
                                              yOdr, XOdr, locsOdrRel, 
                                              NNarray)
      likObj$loglik <- likObj$loglik - penfun(theta)
      likObj$grad <- likObj$grad - dpenfun(theta)
      likObj$info <- likObj$info + ddpenfun(theta)
      likObj
    }
    optObj <- CQCD(objfun, objfun_gdfm, thetaRel, maxIterOut = 20, maxIterIn = 40, 
               lb = lbRel, arg_check = arg_check_SR)
    loglkPen <- gradObj$loglik - penfun(thetaRel)
    loglkPenNew <- optObj$loglik
    if(is.finite(loglkPen))
    {
      improve <- (loglkPenNew - loglkPen) / abs(loglkPen)
      cat("loglkPen improvement:", improve, "\n")
      if(improve < 1e-2)
        break
    }
    # Take out zero relevance
    thetaRel <- optObj$covparms
    idxLocZero <- which(thetaRel[2 : (1 + length(idxNew))] == 0)
    if(length(idxLocZero) > 0)
    {
      cat("Predictor", idxNew[idxLocZero], "are zerod out \n")
      idxNew <- idxNew[-idxLocZero]
      thetaRel <- thetaRel[-(idxLocZero + 1)]
    }
    # Benchmark for next iter
    idx <- idxNew
    theta <- rep(0, d + 2)
    theta[c(1, idx, d + 2)] <- thetaRel
    # loglkPen <- loglkPenNew
  }
  cat("lambda =", lambda, "idx =", idx, "\n\n")
  return(list(lambda = lambda, theta = theta, idx = idx, loglik = gradObj$loglik, 
              grad = gradObj$grad))
}
```

Storage variabels for plotting later.
```{r lambda grid, eval = T}
# define result collecting vars
idxSet <- list()
thetaSet <- list()
scoreSet <- list()
lambdaSet <- list()
loglikSet <- list()
```
Initialization.
```{r nitialization, eval = T}
sigmasqInit <- 0.25
tausqInit <- 0.01^2
theta0 <- c(sigmasqInit, rep(1e-8, d), tausqInit)
lb <- c(0.01^2, rep(0, d), 0.01^2) 
arg_check_SR <- function(x) {sum(sqrt(x[-c(1, length(x))])) > 1e-4}
arg_check_R <- function(x) {sum(x[-c(1, length(x))]) > 1e-4}
idx <- c()
XOdr <- X
yOdr <- y
locsOdr <- locs
NNarray <- find_ordered_nn(locs, m = m)
grad <- vecchia_profbeta_loglik_grad_info(theta0, 
                                          "matern25_scaledim_sqrelevance",
                                          yOdr, XOdr, locsOdr, NNarray)$grad
```


Loop over lambda
```{r loop over lambda, eval = T}
niter <- 5
startTime <- Sys.time()
for(i in 1 : niter)
{
  cat("\n====================================\n")
  cat("i =", i, "\n")
  # select covariates
  lambda0 <- 4 * max(0, grad[setdiff(2 : (d + 1), idx)])
  c <- 1
  cPrev <- 1
  cScale <- lambda0
  while(TRUE)
  {
    # Define lambda
    lambda = lambda0 + (c - 1.0) * cScale
    cat("lambda = ", lambda, "\n")
    # Fit model with lambda
    optObj <- fit_order_select_SR(lambda)
    # Check if the number of new predictors is 1
    if(length(optObj$idx) == i)
      break
    else if(c >= cPrev && length(optObj$idx) > i)
    {
      cPrev <- c
      c <- c + 0.125
    }
    else if(c <= cPrev && length(optObj$idx) < i)
    {
      cPrev <- c
      c <- max(c - 0.125, 0)
      if(c == 0) # not fitting with zero because it's time costly
      {
        cat("\nCannot find proper c for lambda. Changing lambda0\n\n")
        lambda0 <- lambda0 + ((cPrev - 1.0) * cScale + (c - 1.0) * cScale) / 2
        cScale <- abs(cPrev - c) * cScale / 2
        c <- 1
        cPrev <- 1
        next
      }
    }
    else 
    {
      cat("\nCannot find proper c for lambda. Changing lambda0\n\n")
      lambda0 <- lambda0 + ((cPrev - 1.0) * cScale + (c - 1.0) * cScale) / 2
      cScale <- abs(cPrev - c) * cScale / 2
      c <- 1
      cPrev <- 1
      next
    }
  }
  grad <- optObj$grad
  idx <- optObj$idx
  # Store results
  idxSet[[i]] <- optObj$idx
  thetaSet[[i]] <- optObj$theta
  scoreSet[[i]] <- CV_score(optObj$theta)
  lambdaSet[[i]] <- lambda
  loglikSet[[i]] <- optObj$loglik
}
```

```{r save the result}
save.image(file = "stepk_indep_logistic_v4.RData")
```

## Verdict




